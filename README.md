---

# üß† SHL Assessment Recommendation Engine

An **AI-powered semantic recommendation system** that suggests suitable SHL-style assessments based on a given **job description or required skills**.
The system uses **embedding-based similarity search** instead of rule-based filtering to provide intelligent, scalable recommendations.

---

## üìå Table of Contents

1. Project Overview
2. Problem Statement
3. Solution Approach
4. Tech Stack
5. Project Architecture
6. Dataset Strategy
7. Why Web Scraping Failed (Important)
8. Custom Dataset Creation
9. Installation & Setup
10. How to Run the Project
11. File & Folder Structure
12. Use Cases
13. Design Decisions
14. Evaluation Strategy
15. API Endpoint (Backend)
16. Limitations
17. Future Improvements

---

üîó **Live Demo:** [https://shl-internship-task-qo8cearcp2tq2dnxquqvsl.streamlit.app/](https://shl-internship-task-qo8cearcp2tq2dnxquqvsl.streamlit.app/)

---

## 1Ô∏è‚É£ Project Overview

Hiring teams often struggle to decide **which assessments best match a role**.
This project solves that problem by building a **semantic recommendation engine** that:

* Understands job descriptions
* Matches them with assessment metadata
* Returns the most relevant assessments using vector similarity

The focus is on **system design and recommendation logic**, not UI-heavy features.

---

## 2Ô∏è‚É£ Problem Statement

> Given a job description or required skills, recommend the most suitable SHL assessments.

Constraints:

* No official public SHL API
* Assessment pages are dynamically rendered
* Data availability is limited

---

## 3Ô∏è‚É£ Solution Approach

Instead of traditional rule-based matching, this system uses:

* **Sentence embeddings** to represent text semantically
* **FAISS** for fast similarity search
* **Streamlit** for interactive UI

### High-level flow:

```
Job Description ‚Üí Embedding ‚Üí FAISS Search ‚Üí Ranked Assessments
```

---

## 4Ô∏è‚É£ Tech Stack

| Layer         | Technology                     |
| ------------- | ------------------------------ |
| Language      | Python                         |
| Data Handling | Pandas                         |
| NLP           | Sentence-Transformers (MiniLM) |
| Vector DB     | FAISS                          |
| UI            | Streamlit                      |
| Backend API   | FastAPI + Uvicorn              |
| Chunking      | LangChain Text Splitters       |
| Evaluation    | Precision@K, Hit Rate@K        |

---

## 5Ô∏è‚É£ Project Architecture

```
SHL/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ shl_assessments.csv
‚îÇ
‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îú‚îÄ‚îÄ text_builder.py
‚îÇ   ‚îî‚îÄ‚îÄ chunker.py
‚îÇ
‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îú‚îÄ‚îÄ embedder.py
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py
‚îÇ   ‚îî‚îÄ‚îÄ build_index.py
‚îÇ
‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îú‚îÄ‚îÄ retriever.py
‚îÇ   ‚îî‚îÄ‚îÄ ranker.py
‚îÇ
‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îî‚îÄ‚îÄ evaluation_queries.json
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îî‚îÄ‚îÄ parser.py
‚îÇ
‚îú‚îÄ‚îÄ faiss_index/
‚îÇ   ‚îî‚îÄ‚îÄ shl.index
‚îÇ
‚îú‚îÄ‚îÄ app.py              # Streamlit UI
‚îú‚îÄ‚îÄ api.py              # FastAPI backend
‚îî‚îÄ‚îÄ README.md
```

---

## 6Ô∏è‚É£ Dataset Strategy

### Why data is required

The recommendation engine needs **assessment metadata** such as:

* Assessment name
* Skills measured
* Job roles
* Description
* Duration

This data is converted into **semantic embeddings**.

---

## 7Ô∏è‚É£ Why Web Scraping Failed (IMPORTANT)

We initially attempted to scrape assessment data using **BeautifulSoup**.

### Issues encountered:

* ‚ùå No stable public SHL API
* ‚ùå Assessment pages are **JavaScript-rendered**
* ‚ùå URLs frequently return **404**
* ‚ùå Dynamic content not accessible via Requests
* ‚ùå Legal & ethical concerns for scraping proprietary data

### Engineering decision:

> Stop fighting unstable scraping and focus on the **core recommendation system**.

üìå This is a **real-world engineering choice**, not a shortcut.

---

## 8Ô∏è‚É£ Custom Dataset Creation (Why & How)

To proceed safely and reliably, we created a **curated dataset** inspired by the **SHL Product Catalogue**.

### Why this approach is valid:

* Demonstrates full pipeline functionality
* Avoids legal and scraping issues
* Keeps system **scalable**
* Aligns with real-world engineering constraints

### Dataset format:

`data/processed/shl_assessments.csv`

```csv
assessment_name,assessment_type,skills_measured,job_roles,description,duration
Numerical Reasoning Test,Cognitive,"Numerical ability,Data interpretation","Data Analyst","Analyzes numerical data",25 minutes
```

---

## 9Ô∏è‚É£ Installation & Setup

### üîπ Create virtual environment

```bash
conda create -n shl python=3.13
conda activate shl
```

### üîπ Install dependencies

```bash
pip install -r requirements.txt
```

---

## üîü How to Run the Project

### Step 1: Build FAISS Index

```bash
python -m embeddings.build_index
```

### Step 2: Run Streamlit App (Frontend)

```bash
streamlit run app.py
```

### Step 3: Run FastAPI Backend

```bash
uvicorn api:app --reload
```

Swagger UI available at:

```
http://127.0.0.1:8000/docs
```

---

## 1Ô∏è‚É£1Ô∏è‚É£ File Responsibilities

| File              | Purpose                                |
| ----------------- | -------------------------------------- |
| `text_builder.py` | Converts CSV rows to rich text         |
| `chunker.py`      | Splits text into overlapping chunks    |
| `embedder.py`     | Loads embedding model                  |
| `build_index.py`  | Builds FAISS index                     |
| `retriever.py`    | Performs semantic search               |
| `ranker.py`       | Removes duplicates                     |
| `parser.py`       | Converts raw text to structured output |
| `evaluation.py`   | Precision@K & Hit Rate@K evaluation    |
| `api.py`          | REST API backend                       |
| `app.py`          | UI + pipeline integration              |

---

## 1Ô∏è‚É£2Ô∏è‚É£ Use Cases

* HR teams selecting assessments
* Recruiters screening roles
* Talent analytics platforms
* Internal HR tooling
* AI-driven hiring assistants

---

## 1Ô∏è‚É£3Ô∏è‚É£ Key Design Decisions

* **Embedding-based retrieval** instead of keyword matching
* **FAISS** for scalable similarity search
* **Curated dataset** over unstable scraping
* **Decoupled UI and API layers**
* **Minimal UI** to highlight core logic

---

## 1Ô∏è‚É£4Ô∏è‚É£ Evaluation Strategy

Since no labeled dataset was provided, **classification accuracy was not suitable**.

### Metrics used:

* **Precision@K** ‚Äì relevance of top-K recommendations
* **Hit Rate@K** ‚Äì presence of at least one relevant assessment

A small curated evaluation set was used, and results are displayed directly in the UI for transparency.

---

## 1Ô∏è‚É£5Ô∏è‚É£ API Endpoint (Backend)

A REST API was implemented using **FastAPI** to expose the recommendation logic.

### Endpoint:

```
POST /recommend
```

### Input:

```json
{
  "query": "Data analyst with strong numerical skills",
  "top_k": 5
}
```

### Output:

```json
{
  "query": "...",
  "recommendations": [
    {
      "name": "...",
      "type": "...",
      "skills": "...",
      "roles": "...",
      "duration": "...",
      "description": "..."
    }
  ]
}
```

The API enables programmatic access and external system integration while keeping the UI independent.

---

## 1Ô∏è‚É£6Ô∏è‚É£ Limitations

* Dataset size is limited
* No real-time SHL API integration
* Recommendations are unsupervised and semantic

---

## 1Ô∏è‚É£7Ô∏è‚É£ Future Improvements

* Expand dataset coverage
* Add similarity score explanations
* Introduce feedback-based re-ranking
* Integrate LLM-based explanation layer
* Fully connect UI with backend API

---

## ‚úÖ Final Note

This project focuses on **core system design, semantic relevance, proper evaluation, and clean deployment practices**, aligned with real-world constraints.

---


